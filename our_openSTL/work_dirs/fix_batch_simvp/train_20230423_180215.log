2023-04-23 18:02:15,580 - Environment info:
------------------------------------------------------------
sys.platform: darwin
Python: 3.10.10 | packaged by conda-forge | (main, Mar 24 2023, 20:17:34) [Clang 14.0.6 ]
CUDA available: False
GCC: Apple clang version 14.0.3 (clang-1403.0.22.14.1)
PyTorch: 2.0.0
PyTorch compiling details: PyTorch built with:
  - GCC 4.2
  - C++ Version: 201703
  - clang 13.1.6
  - Intel(R) oneAPI Math Kernel Library Version 2022.1-Product Build 20220312 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201811
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: NO AVX
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CXX_COMPILER=/Applications/Xcode_13.3.1.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/bin/clang++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -Wno-deprecated-declarations -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOCUPTI -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DUSE_PYTORCH_METAL_EXPORT -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -DUSE_COREML_DELEGATE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=braced-scalar-init -Werror=range-loop-construct -Werror=bool-operation -Winconsistent-missing-override -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wvla-extension -Wno-range-loop-analysis -Wno-pass-failed -Wsuggest-override -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -Wconstant-conversion -Wno-invalid-partial-specialization -Wno-typedef-redefinition -Wno-unused-private-field -Wno-inconsistent-missing-override -Wno-constexpr-not-const -Wno-missing-braces -Wunused-lambda-capture -Wunused-local-typedef -Qunused-arguments -fcolor-diagnostics -fdiagnostics-color=always -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -DUSE_MPS -fno-objc-arc -Wno-unguarded-availability-new -Wno-unused-private-field -Wno-missing-braces -Wno-constexpr-not-const, LAPACK_INFO=mkl, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=OFF, TORCH_VERSION=2.0.0, USE_CUDA=0, USE_CUDNN=OFF, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=OFF, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

TorchVision: 0.15.1
OpenCV: 4.7.0
openstl: 0.2.0
------------------------------------------------------------

2023-04-23 18:02:17,517 - 
device: 	cpu	
dist: 	False	
display_step: 	10	
res_dir: 	work_dirs	
ex_name: 	fix_batch_simvp	
use_gpu: 	False	
fp16: 	True	
torchscript: 	False	
seed: 	42	
diff_seed: 	False	
fps: 	False	
empty_cache: 	True	
find_unused_parameters: 	False	
resume_from: 	None	
auto_resume: 	False	
test: 	False	
deterministic: 	False	
launcher: 	none	
local_rank: 	0	
port: 	29500	
batch_size: 	4	
val_batch_size: 	1	
num_workers: 	4	
data_root: 	../Dataset_Student_V2	
dataname: 	clevrer	
pre_seq_length: 	11	
aft_seq_length: 	11	
total_length: 	22	
method: 	simvp	
config_file: 	None	
model_type: 	None	
drop: 	0.0	
drop_path: 	0	
epoch: 	2	
log_step: 	1	
opt: 	adam	
opt_eps: 	None	
opt_betas: 	None	
momentum: 	0.9	
weight_decay: 	0.0	
clip_grad: 	None	
clip_mode: 	norm	
sched: 	onecycle	
lr: 	0.001	
lr_k_decay: 	1.0	
warmup_lr: 	1e-05	
min_lr: 	1e-06	
final_div_factor: 	10000.0	
warmup_epoch: 	5	
decay_epoch: 	100	
decay_rate: 	0.1	
filter_bias_and_bn: 	False	
spatio_kernel_enc: 	3	
spatio_kernel_dec: 	3	
hid_S: 	64	
hid_T: 	512	
N_T: 	8	
N_S: 	4	
in_shape: 	[11, 3, 160, 240]	
2023-04-23 18:02:19,773 - Model info:
SimVP_Model(
  (enc): Encoder(
    (enc): Sequential(
      (0): ConvSC(
        (conv): BasicConv2d(
          (conv): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (norm): GroupNorm(2, 64, eps=1e-05, affine=True)
          (act): SiLU(inplace=True)
        )
      )
      (1): ConvSC(
        (conv): BasicConv2d(
          (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
          (norm): GroupNorm(2, 64, eps=1e-05, affine=True)
          (act): SiLU(inplace=True)
        )
      )
      (2): ConvSC(
        (conv): BasicConv2d(
          (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (norm): GroupNorm(2, 64, eps=1e-05, affine=True)
          (act): SiLU(inplace=True)
        )
      )
      (3): ConvSC(
        (conv): BasicConv2d(
          (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
          (norm): GroupNorm(2, 64, eps=1e-05, affine=True)
          (act): SiLU(inplace=True)
        )
      )
    )
  )
  (dec): Decoder(
    (dec): Sequential(
      (0): ConvSC(
        (conv): BasicConv2d(
          (conv): Sequential(
            (0): Conv2d(64, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            (1): PixelShuffle(upscale_factor=2)
          )
          (norm): GroupNorm(2, 64, eps=1e-05, affine=True)
          (act): SiLU(inplace=True)
        )
      )
      (1): ConvSC(
        (conv): BasicConv2d(
          (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (norm): GroupNorm(2, 64, eps=1e-05, affine=True)
          (act): SiLU(inplace=True)
        )
      )
      (2): ConvSC(
        (conv): BasicConv2d(
          (conv): Sequential(
            (0): Conv2d(64, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            (1): PixelShuffle(upscale_factor=2)
          )
          (norm): GroupNorm(2, 64, eps=1e-05, affine=True)
          (act): SiLU(inplace=True)
        )
      )
      (3): ConvSC(
        (conv): BasicConv2d(
          (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (norm): GroupNorm(2, 64, eps=1e-05, affine=True)
          (act): SiLU(inplace=True)
        )
      )
    )
    (readout): Conv2d(64, 3, kernel_size=(1, 1), stride=(1, 1))
  )
  (hid): MidMetaNet(
    (enc): Sequential(
      (0): MetaBlock(
        (block): GASubBlock(
          (norm1): BatchNorm2d(704, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (attn): SpatialAttention(
            (proj_1): Conv2d(704, 704, kernel_size=(1, 1), stride=(1, 1))
            (activation): GELU(approximate='none')
            (spatial_gating_unit): AttentionModule(
              (conv0): Conv2d(704, 704, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=704)
              (conv_spatial): Conv2d(704, 704, kernel_size=(7, 7), stride=(1, 1), padding=(9, 9), dilation=(3, 3), groups=704)
              (conv1): Conv2d(704, 1408, kernel_size=(1, 1), stride=(1, 1))
            )
            (proj_2): Conv2d(704, 704, kernel_size=(1, 1), stride=(1, 1))
          )
          (drop_path): DropPath(drop_prob=0.010)
          (norm2): BatchNorm2d(704, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (mlp): MixMlp(
            (fc1): Conv2d(704, 5632, kernel_size=(1, 1), stride=(1, 1))
            (dwconv): DWConv(
              (dwconv): Conv2d(5632, 5632, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=5632)
            )
            (act): GELU(approximate='none')
            (fc2): Conv2d(5632, 704, kernel_size=(1, 1), stride=(1, 1))
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (reduction): Conv2d(704, 512, kernel_size=(1, 1), stride=(1, 1))
      )
      (1): MetaBlock(
        (block): GASubBlock(
          (norm1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (attn): SpatialAttention(
            (proj_1): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))
            (activation): GELU(approximate='none')
            (spatial_gating_unit): AttentionModule(
              (conv0): Conv2d(512, 512, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=512)
              (conv_spatial): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(9, 9), dilation=(3, 3), groups=512)
              (conv1): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1))
            )
            (proj_2): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))
          )
          (drop_path): DropPath(drop_prob=0.009)
          (norm2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (mlp): MixMlp(
            (fc1): Conv2d(512, 4096, kernel_size=(1, 1), stride=(1, 1))
            (dwconv): DWConv(
              (dwconv): Conv2d(4096, 4096, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=4096)
            )
            (act): GELU(approximate='none')
            (fc2): Conv2d(4096, 512, kernel_size=(1, 1), stride=(1, 1))
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
      )
      (2): MetaBlock(
        (block): GASubBlock(
          (norm1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (attn): SpatialAttention(
            (proj_1): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))
            (activation): GELU(approximate='none')
            (spatial_gating_unit): AttentionModule(
              (conv0): Conv2d(512, 512, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=512)
              (conv_spatial): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(9, 9), dilation=(3, 3), groups=512)
              (conv1): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1))
            )
            (proj_2): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))
          )
          (drop_path): DropPath(drop_prob=0.007)
          (norm2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (mlp): MixMlp(
            (fc1): Conv2d(512, 4096, kernel_size=(1, 1), stride=(1, 1))
            (dwconv): DWConv(
              (dwconv): Conv2d(4096, 4096, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=4096)
            )
            (act): GELU(approximate='none')
            (fc2): Conv2d(4096, 512, kernel_size=(1, 1), stride=(1, 1))
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
      )
      (3): MetaBlock(
        (block): GASubBlock(
          (norm1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (attn): SpatialAttention(
            (proj_1): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))
            (activation): GELU(approximate='none')
            (spatial_gating_unit): AttentionModule(
              (conv0): Conv2d(512, 512, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=512)
              (conv_spatial): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(9, 9), dilation=(3, 3), groups=512)
              (conv1): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1))
            )
            (proj_2): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))
          )
          (drop_path): DropPath(drop_prob=0.006)
          (norm2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (mlp): MixMlp(
            (fc1): Conv2d(512, 4096, kernel_size=(1, 1), stride=(1, 1))
            (dwconv): DWConv(
              (dwconv): Conv2d(4096, 4096, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=4096)
            )
            (act): GELU(approximate='none')
            (fc2): Conv2d(4096, 512, kernel_size=(1, 1), stride=(1, 1))
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
      )
      (4): MetaBlock(
        (block): GASubBlock(
          (norm1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (attn): SpatialAttention(
            (proj_1): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))
            (activation): GELU(approximate='none')
            (spatial_gating_unit): AttentionModule(
              (conv0): Conv2d(512, 512, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=512)
              (conv_spatial): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(9, 9), dilation=(3, 3), groups=512)
              (conv1): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1))
            )
            (proj_2): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))
          )
          (drop_path): DropPath(drop_prob=0.004)
          (norm2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (mlp): MixMlp(
            (fc1): Conv2d(512, 4096, kernel_size=(1, 1), stride=(1, 1))
            (dwconv): DWConv(
              (dwconv): Conv2d(4096, 4096, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=4096)
            )
            (act): GELU(approximate='none')
            (fc2): Conv2d(4096, 512, kernel_size=(1, 1), stride=(1, 1))
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
      )
      (5): MetaBlock(
        (block): GASubBlock(
          (norm1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (attn): SpatialAttention(
            (proj_1): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))
            (activation): GELU(approximate='none')
            (spatial_gating_unit): AttentionModule(
              (conv0): Conv2d(512, 512, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=512)
              (conv_spatial): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(9, 9), dilation=(3, 3), groups=512)
              (conv1): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1))
            )
            (proj_2): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))
          )
          (drop_path): DropPath(drop_prob=0.003)
          (norm2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (mlp): MixMlp(
            (fc1): Conv2d(512, 4096, kernel_size=(1, 1), stride=(1, 1))
            (dwconv): DWConv(
              (dwconv): Conv2d(4096, 4096, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=4096)
            )
            (act): GELU(approximate='none')
            (fc2): Conv2d(4096, 512, kernel_size=(1, 1), stride=(1, 1))
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
      )
      (6): MetaBlock(
        (block): GASubBlock(
          (norm1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (attn): SpatialAttention(
            (proj_1): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))
            (activation): GELU(approximate='none')
            (spatial_gating_unit): AttentionModule(
              (conv0): Conv2d(512, 512, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=512)
              (conv_spatial): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(9, 9), dilation=(3, 3), groups=512)
              (conv1): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1))
            )
            (proj_2): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))
          )
          (drop_path): DropPath(drop_prob=0.001)
          (norm2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (mlp): MixMlp(
            (fc1): Conv2d(512, 4096, kernel_size=(1, 1), stride=(1, 1))
            (dwconv): DWConv(
              (dwconv): Conv2d(4096, 4096, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=4096)
            )
            (act): GELU(approximate='none')
            (fc2): Conv2d(4096, 512, kernel_size=(1, 1), stride=(1, 1))
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
      )
      (7): MetaBlock(
        (block): GASubBlock(
          (norm1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (attn): SpatialAttention(
            (proj_1): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))
            (activation): GELU(approximate='none')
            (spatial_gating_unit): AttentionModule(
              (conv0): Conv2d(512, 512, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=512)
              (conv_spatial): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(9, 9), dilation=(3, 3), groups=512)
              (conv1): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1))
            )
            (proj_2): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))
          )
          (drop_path): Identity()
          (norm2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (mlp): MixMlp(
            (fc1): Conv2d(512, 4096, kernel_size=(1, 1), stride=(1, 1))
            (dwconv): DWConv(
              (dwconv): Conv2d(4096, 4096, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=4096)
            )
            (act): GELU(approximate='none')
            (fc2): Conv2d(4096, 512, kernel_size=(1, 1), stride=(1, 1))
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (reduction): Conv2d(512, 704, kernel_size=(1, 1), stride=(1, 1))
      )
    )
  )
)
| module                           | #parameters or shape   | #flops     |
|:---------------------------------|:-----------------------|:-----------|
| model                            | 48.568M                | 0.164T     |
|  enc.enc                         |  0.113M                |  9.7G      |
|   enc.enc.0.conv                 |   1.92K                |   0.865G   |
|    enc.enc.0.conv.conv           |    1.792K              |    0.73G   |
|    enc.enc.0.conv.norm           |    0.128K              |    0.135G  |
|   enc.enc.1.conv                 |   37.056K              |   3.927G   |
|    enc.enc.1.conv.conv           |    36.928K             |    3.893G  |
|    enc.enc.1.conv.norm           |    0.128K              |    33.792M |
|   enc.enc.2.conv                 |   37.056K              |   3.927G   |
|    enc.enc.2.conv.conv           |    36.928K             |    3.893G  |
|    enc.enc.2.conv.norm           |    0.128K              |    33.792M |
|   enc.enc.3.conv                 |   37.056K              |   0.982G   |
|    enc.enc.3.conv.conv           |    36.928K             |    0.973G  |
|    enc.enc.3.conv.norm           |    0.128K              |    8.448M  |
|  dec                             |  0.37M                 |  39.347G   |
|   dec.dec                        |   0.37M                |   39.266G  |
|    dec.dec.0.conv                |    0.148M              |    3.927G  |
|    dec.dec.1.conv                |    37.056K             |    3.927G  |
|    dec.dec.2.conv                |    0.148M              |    15.707G |
|    dec.dec.3.conv                |    37.056K             |    15.707G |
|   dec.readout                    |   0.195K               |   81.101M  |
|    dec.readout.weight            |    (3, 64, 1, 1)       |            |
|    dec.readout.bias              |    (3,)                |            |
|  hid.enc                         |  48.085M               |  0.115T    |
|   hid.enc.0                      |   10.396M              |   24.908G  |
|    hid.enc.0.block               |    10.036M             |    24.043G |
|    hid.enc.0.reduction           |    0.361M              |    0.865G  |
|   hid.enc.1.block                |   5.332M               |   12.767G  |
|    hid.enc.1.block.layer_scale_1 |    (512,)              |            |
|    hid.enc.1.block.layer_scale_2 |    (512,)              |            |
|    hid.enc.1.block.norm1         |    1.024K              |    2.458M  |
|    hid.enc.1.block.attn          |    1.09M               |    2.608G  |
|    hid.enc.1.block.norm2         |    1.024K              |    2.458M  |
|    hid.enc.1.block.mlp           |    4.24M               |    10.155G |
|   hid.enc.2.block                |   5.332M               |   12.767G  |
|    hid.enc.2.block.layer_scale_1 |    (512,)              |            |
|    hid.enc.2.block.layer_scale_2 |    (512,)              |            |
|    hid.enc.2.block.norm1         |    1.024K              |    2.458M  |
|    hid.enc.2.block.attn          |    1.09M               |    2.608G  |
|    hid.enc.2.block.norm2         |    1.024K              |    2.458M  |
|    hid.enc.2.block.mlp           |    4.24M               |    10.155G |
|   hid.enc.3.block                |   5.332M               |   12.767G  |
|    hid.enc.3.block.layer_scale_1 |    (512,)              |            |
|    hid.enc.3.block.layer_scale_2 |    (512,)              |            |
|    hid.enc.3.block.norm1         |    1.024K              |    2.458M  |
|    hid.enc.3.block.attn          |    1.09M               |    2.608G  |
|    hid.enc.3.block.norm2         |    1.024K              |    2.458M  |
|    hid.enc.3.block.mlp           |    4.24M               |    10.155G |
|   hid.enc.4.block                |   5.332M               |   12.767G  |
|    hid.enc.4.block.layer_scale_1 |    (512,)              |            |
|    hid.enc.4.block.layer_scale_2 |    (512,)              |            |
|    hid.enc.4.block.norm1         |    1.024K              |    2.458M  |
|    hid.enc.4.block.attn          |    1.09M               |    2.608G  |
|    hid.enc.4.block.norm2         |    1.024K              |    2.458M  |
|    hid.enc.4.block.mlp           |    4.24M               |    10.155G |
|   hid.enc.5.block                |   5.332M               |   12.767G  |
|    hid.enc.5.block.layer_scale_1 |    (512,)              |            |
|    hid.enc.5.block.layer_scale_2 |    (512,)              |            |
|    hid.enc.5.block.norm1         |    1.024K              |    2.458M  |
|    hid.enc.5.block.attn          |    1.09M               |    2.608G  |
|    hid.enc.5.block.norm2         |    1.024K              |    2.458M  |
|    hid.enc.5.block.mlp           |    4.24M               |    10.155G |
|   hid.enc.6.block                |   5.332M               |   12.767G  |
|    hid.enc.6.block.layer_scale_1 |    (512,)              |            |
|    hid.enc.6.block.layer_scale_2 |    (512,)              |            |
|    hid.enc.6.block.norm1         |    1.024K              |    2.458M  |
|    hid.enc.6.block.attn          |    1.09M               |    2.608G  |
|    hid.enc.6.block.norm2         |    1.024K              |    2.458M  |
|    hid.enc.6.block.mlp           |    4.24M               |    10.155G |
|   hid.enc.7                      |   5.694M               |   13.632G  |
|    hid.enc.7.block               |    5.332M              |    12.767G |
|    hid.enc.7.reduction           |    0.361M              |    0.865G  |
--------------------------------------------------------------------------------

2023-04-23 18:04:43,026 - 
val	 mse:1833.5869140625, mae:11493.568359375
2023-04-23 18:04:43,032 - Intermediate result: 1833.5869140625  (Index 0)
2023-04-23 18:04:43,054 - Epoch: 1, Steps: 5 | Lr: 0.0006113 | Train Loss: 0.0635329 | Vali Loss: 0.0159166

2023-04-23 18:07:08,984 - 
val	 mse:1936.4422607421875, mae:12091.958984375
2023-04-23 18:07:08,988 - Intermediate result: 1936.4422607421875  (Index 1)
2023-04-23 18:07:09,008 - Epoch: 2, Steps: 5 | Lr: 0.0000495 | Train Loss: 0.0183296 | Vali Loss: 0.0168094

2023-04-23 18:07:44,357 - mse:1833.5869140625, mae:11493.568359375
2023-04-23 18:07:53,322 - Final result: 1833.5869140625
